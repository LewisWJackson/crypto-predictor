Loading config from: configs/experiments/p1_horizon_15min_agg.yaml
Loading model from: models/tft/tft-epoch=03-val_loss=0.1909.ckpt
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
  Model parameters: 629,536
Creating datasets...
  Filtered to data from 2022-01-01: 175,026 â†’ 105,196 rows
  Test samples: 15453
Running predictions on test set...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.
  Predictions shape: (15453, 4)
  Actuals shape:     (15453, 4)

Computing metrics...
Computing baseline metrics...
======================================================================
EVALUATION REPORT
======================================================================

--- TFT Model ---
  MSE:                         0.000009
  RMSE:                        0.003073
  MAE:                         0.002128
  Directional Acc (all steps): 0.4945
  Directional Acc (step 15):   0.4968
  Win Rate:                    0.4968
  Sharpe Ratio (annualized):   -0.0817
  Total Return:                -0.019121
  Max Drawdown:                0.311892
  Profit Factor:               0.9987

--- Baseline: random ---
  Directional Acc (step 15):   0.4985
  Win Rate:                    0.4985
  Sharpe Ratio (annualized):   0.9757
  Profit Factor:               1.0158

--- Baseline: persistence ---
  Directional Acc (step 15):   0.4862
  Win Rate:                    0.4862
  Sharpe Ratio (annualized):   -3.3601
  Profit Factor:               0.9473

--- Model vs Baselines (Directional Acc @ step 15) ---
  vs random         : -0.0017 (0.4968 vs 0.4985)
  vs persistence    : +0.0106 (0.4968 vs 0.4862)

======================================================================

--- Threshold Check ---
  Directional Acc >= 0.52: 0.4968  FAIL
  Sharpe Ratio   >= 0.50: -0.0817  FAIL
  Max Drawdown   <= 0.20: 0.3119  FAIL

  Overall: SOME THRESHOLDS NOT MET

Report saved to: models/tft/tft-epoch=03-val_loss=0.1909_evaluation.txt
