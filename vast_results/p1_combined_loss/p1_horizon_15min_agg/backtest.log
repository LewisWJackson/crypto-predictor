Loading config from: configs/experiments/p1_horizon_15min_agg.yaml
Loading model from: models/tft/tft-epoch=03-val_loss=0.1909.ckpt
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
  Model parameters: 629,536
Creating datasets...
  Filtered to data from 2022-01-01: 175,026 â†’ 105,196 rows
  Test samples: 15453
Running predictions on test set...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.
  Predictions shape: (15453, 4)
  Actuals shape:     (15453, 4)
Computing metrics...
Simulating long/flat strategy...
Equity curve saved to: /app/models/tft/backtest_equity.png

======================================================================
BACKTEST REPORT â€” TFT Long/Flat Strategy
======================================================================

  Test samples:       15453
  Total trades (long): 8204
  Wins / Losses:       4108 / 4095

  --- P&L Metrics ---
  Cumulative P&L:      0.168435 (log return)
  Sharpe Ratio (ann.): 1.3641
  Max Drawdown:        0.296938
  Win Rate:            0.5007 (50.1%)
  Profit Factor:       1.0224

  --- Model Quality Metrics ---
  Directional Acc (step 15): 0.4968
  Directional Acc (all):     0.4945
  RMSE:                      0.003073
  MAE:                       0.002128

======================================================================
