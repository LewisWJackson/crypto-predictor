/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.
Loading config from: configs/experiments/p1_horizon_15min_agg.yaml
Loading model from: models/tft/tft-epoch=15-val_loss=0.0026.ckpt
  Model parameters: 629,926
Creating datasets...
  Filtered to data from 2022-01-01: 175,026 â†’ 105,196 rows
  Test samples: 15453
Running predictions on test set...
  Predictions shape: (15453, 4)
  Actuals shape:     (15453, 4)

Computing metrics...
Computing baseline metrics...
======================================================================
EVALUATION REPORT
======================================================================

--- TFT Model ---
  MSE:                         0.000008
  RMSE:                        0.002902
  MAE:                         0.001960
  Directional Acc (all steps): 0.5036
  Directional Acc (step 15):   0.5035
  Win Rate:                    0.5035
  Sharpe Ratio (annualized):   1.5218
  Total Return:                0.355992
  Max Drawdown:                0.341215
  Profit Factor:               1.0248

--- Baseline: random ---
  Directional Acc (step 15):   0.4985
  Win Rate:                    0.4985
  Sharpe Ratio (annualized):   0.9757
  Profit Factor:               1.0158

--- Baseline: persistence ---
  Directional Acc (step 15):   0.4862
  Win Rate:                    0.4862
  Sharpe Ratio (annualized):   -3.3601
  Profit Factor:               0.9473

--- Model vs Baselines (Directional Acc @ step 15) ---
  vs random         : +0.0050 (0.5035 vs 0.4985)
  vs persistence    : +0.0173 (0.5035 vs 0.4862)

======================================================================

--- Threshold Check ---
  Directional Acc >= 0.52: 0.5035  FAIL
  Sharpe Ratio   >= 0.50: 1.5218  PASS
  Max Drawdown   <= 0.20: 0.3412  FAIL

  Overall: SOME THRESHOLDS NOT MET

Report saved to: models/tft/tft-epoch=15-val_loss=0.0026_evaluation.txt
